## Part 1 - Introduction to Neural Networks 

### Decision Boundary 
![](./img/L1_decision_boundary.png)
![](./img/L1_decision_boundary2.png) 

### Perceptron
![](./img/L1_perceptron.png) 
![](./img/L1_perceptron_trick.png)  
Moving the line closer to the point by multiply the learning rate with a vector from point (a,b) - [a, b, 1] and subtract or add to the original weights and bias. If misclassified point's prediction is 1, then subtract. Otherwise, add. 

### Perceptron Algorithm 
![](./img/L1_perceptron_algo.png)
![](./img/L1_perceptron_algo2.png)

### Activation Function 
![](./img/L1_sigmoid.png) 
![](./img/L1_sigmoid2.png) 

### Error Function 
* Continuous error functions are better than discrete error functions, when it comes to optimizing. 

### Softmax
![](./img/L1_softmax.png) 

### Logistic Regression
![](./img/L1_logistic_reg.png)   
__gradient descent for logistic regression__

![](./img/L1_GD_for_LR.png)
![](./img/L1_GD_for_LR2.png)
![](./img/L1_GD_for_LR3.png)
![](./img/L1_GD_for_LR4.png)
![](./img/L1_GD_for_LR5.png)

### Neural Network 

![](./img/L1_NN1.png)
![](./img/L1_NN2.png)
![](./img/L1_NN3.png)
![](./img/L1_NN4.png)
![](./img/L1_NN5.png)
![](./img/L1_NN6.png) 

### Neural Network Computation and Backpropagation 
- Doing a feedforward operation.
- Comparing the output of the model with the desired output.
- Calculating the error.
- Running the feedforward operation backwards (backpropagation) to spread the error to each of the weights.
- Use this to update the weights, and get a better model.
- Continue this until we have a model that is good.

![](./img/L1_NN_Computation1.png)
![](./img/L1_NN_Computation2.png)
![](./img/L1_NN_Computation3.png)
![](./img/L1_NN_Computation4.png)
![](./img/L1_NN_Computation5.png)
![](./img/L1_NN_Computation6.png)
![](./img/L1_NN_Computation7.png)